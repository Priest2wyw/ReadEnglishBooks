# README 

工作半年来，觉得自己的计算机底子太差了，想补一下基础。`阅读计算机经典著作是提升基础最快的方法。`但很多的计算机经典读起来特别痛苦，主要问题在于：

-   英文原著：
    -   读的很慢：主要问题在单词上面，自己词汇量不够，每次遇到生词时候，总是读的云里雾里的。还有很多专有词汇
-   中文翻译：
    -   质量太差：很多经典的书，原著是很好的，但是被人翻译的乱七八糟的。甚至最后不如直接看英文原著来的快。
    -   没有翻译：很多很好的英文原著是不存在中文翻译的。

最终，为了自己的成长，我还是选择读英文原著。为了能够提升读书的效率，做到想读即读，我决定使用词频统计的方法，来解决单词这关。

## 关于背单词的声明

之前为了考试，我也抱着一本本单词书背过，时间长见效慢，还常常因为毅力读不下来。这是一种一次性解决单词问题的方案，我身边有很多同学也在这种方法下面取得了比较好的方法。关于学习英语，这不妨是一种提升最快的方案。

但是，如果你只是想为了读一本书，而要去把全部的单词背掉显得很愚蠢。好几次，都是单词背一半，想看什么书都忘了。这不是本末倒置了。

**该项目，只是致力于给出阅读一本英文书，最小的单词集合。从而花尽可能少的时间，让词汇量达到阅读某一本书的水平。**希望大家在读书过程中，少查字典，把更多的时间放在理解原文上面。

## 基本架构

```python
input:pdf(要求可编辑那种)
output:频率从高到低的单词列表
```

本文词频统计和翻译部分，借鉴了**[count_word_frequency](https://github.com/yangzhaonan18/count_word_frequency)**的代码。

-----------------------------------------------





## 1. 功能说明：

程序执行 `python3 main.py ` 运行结果如下：

```
Number of all words : 18874
Translation results : 1 13432 --> the : 这个
Translation results : 2 4632 --> and : 和
Translation results : 3 2479 --> are : 是
Translation results : 4 2364 --> that : 那个
Translation results : 5 2326 --> for : 对于
Translation results : 6 1962 --> they : 他们
Translation results : 7 1919 --> you : 你
Translation results : 8 1675 --> with : 具有
Translation results : 9 1580 --> have : 有

```

保存的 resutls.xlsx 内容如下：

| 编号 | 频数 | 待翻译单词 | 翻译结果 | 
|--|--|--|--|
| 1 | 13432 | the  | 这个 |
|  2| 4632| and | 和 |  
| 3 | 2479 | are  | 是 |  
| 4 |2364  | that | 那个 | 
| 5 | 2326 | for | 对于 | 


## 2. 使用说明：

1. main.py 

程序用于统计 CET6_txt 文件夹中 .txt 文档中的单词的频数，最总结果将保存在 results.xlsx 中。

程序流程：1. 读取各个文档中的内容；2. 将单词按降序排列；3. 调用百度翻译API翻译每一个单词并保存至excel文档。

2. BaiduTransAPI_forPython3.py 

程序是从百度翻译API下载的翻译DEMO文件.官网链接：http://api.fanyi.baidu.com/doc/21

程序流程：1. 输入英文单词或句子；2. 返回调用百度翻译API翻译的结果。

3. 上述两个文件可单独运行，无交集。

## 3. 其他说明：

暂无
